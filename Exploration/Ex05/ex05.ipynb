{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:46.667424Z",
     "start_time": "2025-08-01T08:30:45.189159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, random, math, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "print(\"TF   :\", tf.__version__)\n",
    "print(\"GPU devices visible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import pandas as pandas_lib\n",
    "import konlpy as konlpy_lib\n",
    "import gensim as gensim_lib\n",
    "print(\"pandas:\", pandas_lib.__version__)\n",
    "print(\"konlpy:\", konlpy_lib.__version__)\n",
    "print(\"gensim:\", gensim_lib.__version__)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for g in gpus:\n",
    "            tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass"
   ],
   "id": "9b0365d5774a1cfb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:30:45.574650: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-01 17:30:45.591721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-01 17:30:45.591746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-01 17:30:45.592213: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-01 17:30:45.595651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-01 17:30:45.994456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF   : 2.15.1\n",
      "GPU devices visible: []\n",
      "pandas: 2.3.1\n",
      "konlpy: 0.6.0\n",
      "gensim: 4.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:30:46.651647: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-01 17:30:46.664838: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:46.919851Z",
     "start_time": "2025-08-01T08:30:46.710221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_path = './data/ratings_train.txt'\n",
    "test_path  = './data/ratings_test.txt'\n",
    "\n",
    "train_df = pd.read_table(train_path)\n",
    "test_df = pd.read_table(test_path)\n",
    "\n",
    "train_df = train_df.drop_duplicates(subset=['document']).dropna(how='any').reset_index(drop=True)\n",
    "test_df  = test_df.drop_duplicates(subset=['document']).dropna(how='any').reset_index(drop=True)\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "train_df.head()"
   ],
   "id": "2af16c9281bcc518",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 3) (49157, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:46.942024Z",
     "start_time": "2025-08-01T08:30:46.938914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab(dicpath=\"/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic\")\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ],
   "id": "c08e3d516026cc0f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:52.506812Z",
     "start_time": "2025-08-01T08:30:47.122550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(sent):\n",
    "    toks = tokenizer.morphs(sent)\n",
    "    toks = [t for t in toks if t not in stopwords]\n",
    "    return toks\n",
    "\n",
    "X_train_tokens = [tokenize(s) for s in train_df['document']]\n",
    "X_test_tokens  = [tokenize(s) for s in test_df['document']]\n",
    "y_train = train_df['label'].astype(int).values\n",
    "y_test  = test_df['label'].astype(int).values"
   ],
   "id": "bf0645195ce1f9ad",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:53.222877Z",
     "start_time": "2025-08-01T08:30:52.554260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "special_tokens = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>']\n",
    "\n",
    "# 빈도수 상위 num_words-4 사용\n",
    "num_words = 10000\n",
    "all_words = list(chain.from_iterable(X_train_tokens))\n",
    "counter = Counter(all_words).most_common(num_words - len(special_tokens))\n",
    "vocab = special_tokens + [w for w, _ in counter]\n",
    "\n",
    "word_to_index = {w:i for i, w in enumerate(vocab)}\n",
    "index_to_word = {i:w for w,i in word_to_index.items()}\n",
    "\n",
    "def words_to_indices(tokens):\n",
    "    return [word_to_index.get(t, word_to_index['<UNK>']) for t in tokens]\n",
    "\n",
    "X_train_ids = [[word_to_index['<BOS>']] + words_to_indices(ts) for ts in X_train_tokens]\n",
    "X_test_ids  = [[word_to_index['<BOS>']] + words_to_indices(ts)  for ts in X_test_tokens]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)"
   ],
   "id": "73eeaced42e6b00f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 10000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:53.314860Z",
     "start_time": "2025-08-01T08:30:53.235823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lengths = np.array([len(x) for x in X_train_ids])\n",
    "print(\"문장 길이 통계 — min:{}, max:{}, mean:{:.1f}, 95%:{:.0f}, 99%:{:.0f}\".format(\n",
    "    lengths.min(), lengths.max(), lengths.mean(), np.percentile(lengths,95), np.percentile(lengths,99)\n",
    "))\n",
    "\n",
    "# 히스토그램(분포)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title(\"Train 문장 길이 분포\")\n",
    "plt.xlabel(\"length\"); plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "MAX_LEN = int(np.percentile(lengths, 95))\n",
    "MAX_LEN = max(20, min(MAX_LEN, 200))  # 안전한 범위로 클리핑\n",
    "print(\"선정된 MAX_LEN:\", MAX_LEN)"
   ],
   "id": "ab8466353c806e0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이 통계 — min:1, max:117, mean:17.0, 95%:48, 99%:62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선정된 MAX_LEN: 48\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:53.534780Z",
     "start_time": "2025-08-01T08:30:53.340287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_pad = pad_sequences(X_train_ids, maxlen=MAX_LEN, padding='post', truncating='post', value=word_to_index['<PAD>'])\n",
    "X_test_pad  = pad_sequences(X_test_ids,  maxlen=MAX_LEN, padding='post', truncating='post', value=word_to_index['<PAD>'])"
   ],
   "id": "7aeb18ecd32c7946",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:53.552647Z",
     "start_time": "2025-08-01T08:30:53.547857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_fasttext_like(vocab_size, embed_dim=128, maxlen=MAX_LEN):\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True, name=\"emb\")(inp)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    m = models.Model(inp, out, name=\"FastTextLike\")\n",
    "    m.compile(optimizer=optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def build_cnn(vocab_size, embed_dim=128, maxlen=MAX_LEN):\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True, name=\"emb\")(inp)\n",
    "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    m = models.Model(inp, out, name=\"TextCNN\")\n",
    "    m.compile(optimizer=optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def build_bilstm(vocab_size, embed_dim=128, maxlen=MAX_LEN):\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(vocab_size, embed_dim, mask_zero=True, name=\"emb\")(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    m = models.Model(inp, out, name=\"BiLSTM\")\n",
    "    m.compile(optimizer=optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m\n"
   ],
   "id": "c876fe90d2e00e65",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:56.274540Z",
     "start_time": "2025-08-01T08:30:53.615388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word2vec_file_path = './data/word2vec_ko.model'\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "kv = word_vectors.wv\n",
    "\n",
    "w2v_dim = kv.vector_size\n",
    "print(f\"Loaded embeddings: {word2vec_file_path}, dim: {w2v_dim}\")"
   ],
   "id": "b92768a8ed7766ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: ./data/word2vec_ko.model, dim: 100\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:56.319540Z",
     "start_time": "2025-08-01T08:30:56.288445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_matrix = np.random.normal(loc=0.0, scale=0.05, size=(vocab_size, w2v_dim)).astype(np.float32)\n",
    "embedding_matrix[word_to_index['<PAD>']] = 0.0  # PAD는 0 벡터\n",
    "\n",
    "hit = 0\n",
    "for w, idx in word_to_index.items():\n",
    "    if w in special_tokens:\n",
    "        continue\n",
    "\n",
    "    if kv.has_index_for(w):\n",
    "        embedding_matrix[idx] = kv[w]\n",
    "        hit += 1\n",
    "\n",
    "print(f\"Pretrained coverage: {hit}/{vocab_size} ({100*hit/vocab_size:.1f}%)\")"
   ],
   "id": "d5a4ac878d42f5d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained coverage: 9457/10000 (94.6%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:30:56.336107Z",
     "start_time": "2025-08-01T08:30:56.333282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 사전학습 임베딩 주입 BiLSTM (freeze/finetune용) ---\n",
    "def build_bilstm_pretrained(vocab_size, embedding_matrix, maxlen=MAX_LEN, trainable=False):\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    x = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_matrix.shape[1],  # w2v_dim\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=trainable,\n",
    "        mask_zero=True,\n",
    "        name=\"emb_pre\"\n",
    "    )(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    m = models.Model(inp, out, name=f\"BiLSTM_W2V_trainable_{trainable}\")\n",
    "    m.compile(optimizer=optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m\n"
   ],
   "id": "39115ac27d95cdf1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:40:47.941471Z",
     "start_time": "2025-08-01T08:30:56.396168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH = 128\n",
    "EPOCHS = 15\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def train_and_eval(model, name):\n",
    "    h = model.fit(X_train_pad, y_train, validation_split=0.2,\n",
    "                  epochs=EPOCHS, batch_size=BATCH, callbacks=[es], verbose=1)\n",
    "    loss, acc = model.evaluate(X_test_pad, y_test, batch_size=BATCH, verbose=0)\n",
    "    print(f\"[{name}] Test Acc: {acc*100:.2f}%\")\n",
    "    return h, (loss, acc)\n",
    "\n",
    "# 베이스라인 3종\n",
    "m_ft = build_fasttext_like(vocab_size, embed_dim=128, maxlen=MAX_LEN)\n",
    "h_ft, s_ft = train_and_eval(m_ft, \"FastTextLike\")\n",
    "\n",
    "m_cnn  = build_cnn(vocab_size, embed_dim=128, maxlen=MAX_LEN)\n",
    "h_cnn, s_cnn = train_and_eval(m_cnn, \"TextCNN\")\n",
    "\n",
    "m_bi   = build_bilstm(vocab_size, embed_dim=128, maxlen=MAX_LEN)\n",
    "h_bi, s_bi = train_and_eval(m_bi, \"BiLSTM\")\n",
    "\n",
    "# W2V사용 (freeze → finetune)\n",
    "m_w2v_frozen = build_bilstm_pretrained(vocab_size, embedding_matrix, trainable=False)\n",
    "h_w2v_frozen, s_w2v_frozen = train_and_eval(m_w2v_frozen, \"BiLSTM_W2V_Frozen\")\n",
    "\n",
    "m_w2v_ft = build_bilstm_pretrained(vocab_size, embedding_matrix, trainable=True)\n",
    "\n",
    "# 파인튜닝은 보통 더 낮은 lr가 안정적\n",
    "m_w2v_ft.compile(optimizer=optimizers.Adam(5e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "h_w2v_ft, s_w2v_ft = train_and_eval(m_w2v_ft, \"BiLSTM_W2V_FineTune\")"
   ],
   "id": "e65fef1644a5c7a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "914/914 [==============================] - 5s 5ms/step - loss: 0.4002 - accuracy: 0.8253 - val_loss: 0.3534 - val_accuracy: 0.8449\n",
      "Epoch 2/15\n",
      "914/914 [==============================] - 4s 5ms/step - loss: 0.3276 - accuracy: 0.8585 - val_loss: 0.3534 - val_accuracy: 0.8453\n",
      "Epoch 3/15\n",
      "914/914 [==============================] - 4s 5ms/step - loss: 0.3076 - accuracy: 0.8638 - val_loss: 0.3680 - val_accuracy: 0.8431\n",
      "Epoch 4/15\n",
      "914/914 [==============================] - 5s 5ms/step - loss: 0.2954 - accuracy: 0.8679 - val_loss: 0.3728 - val_accuracy: 0.8440\n",
      "[FastTextLike] Test Acc: 84.42%\n",
      "Epoch 1/15\n",
      "914/914 [==============================] - 7s 8ms/step - loss: 0.3771 - accuracy: 0.8300 - val_loss: 0.3235 - val_accuracy: 0.8589\n",
      "Epoch 2/15\n",
      "914/914 [==============================] - 7s 8ms/step - loss: 0.2614 - accuracy: 0.8935 - val_loss: 0.3188 - val_accuracy: 0.8662\n",
      "Epoch 3/15\n",
      "914/914 [==============================] - 7s 8ms/step - loss: 0.1784 - accuracy: 0.9325 - val_loss: 0.3471 - val_accuracy: 0.8647\n",
      "Epoch 4/15\n",
      "914/914 [==============================] - 7s 8ms/step - loss: 0.1083 - accuracy: 0.9612 - val_loss: 0.4366 - val_accuracy: 0.8578\n",
      "Epoch 5/15\n",
      "914/914 [==============================] - 7s 8ms/step - loss: 0.0675 - accuracy: 0.9761 - val_loss: 0.5373 - val_accuracy: 0.8492\n",
      "[TextCNN] Test Acc: 86.45%\n",
      "Epoch 1/15\n",
      "914/914 [==============================] - 30s 30ms/step - loss: 0.3820 - accuracy: 0.8289 - val_loss: 0.3365 - val_accuracy: 0.8541\n",
      "Epoch 2/15\n",
      "914/914 [==============================] - 26s 29ms/step - loss: 0.2966 - accuracy: 0.8728 - val_loss: 0.3231 - val_accuracy: 0.8636\n",
      "Epoch 3/15\n",
      "914/914 [==============================] - 27s 29ms/step - loss: 0.2482 - accuracy: 0.8959 - val_loss: 0.3286 - val_accuracy: 0.8615\n",
      "Epoch 4/15\n",
      "914/914 [==============================] - 26s 29ms/step - loss: 0.2085 - accuracy: 0.9146 - val_loss: 0.3532 - val_accuracy: 0.8589\n",
      "Epoch 5/15\n",
      "914/914 [==============================] - 26s 29ms/step - loss: 0.1739 - accuracy: 0.9303 - val_loss: 0.3933 - val_accuracy: 0.8519\n",
      "[BiLSTM] Test Acc: 85.93%\n",
      "Epoch 1/15\n",
      "914/914 [==============================] - 26s 26ms/step - loss: 0.4605 - accuracy: 0.7793 - val_loss: 0.4119 - val_accuracy: 0.8102\n",
      "Epoch 2/15\n",
      "914/914 [==============================] - 23s 25ms/step - loss: 0.3803 - accuracy: 0.8278 - val_loss: 0.3757 - val_accuracy: 0.8332\n",
      "Epoch 3/15\n",
      "914/914 [==============================] - 23s 25ms/step - loss: 0.3479 - accuracy: 0.8466 - val_loss: 0.3652 - val_accuracy: 0.8389\n",
      "Epoch 4/15\n",
      "914/914 [==============================] - 22s 24ms/step - loss: 0.3233 - accuracy: 0.8583 - val_loss: 0.3611 - val_accuracy: 0.8411\n",
      "Epoch 5/15\n",
      "914/914 [==============================] - 22s 25ms/step - loss: 0.3017 - accuracy: 0.8693 - val_loss: 0.3638 - val_accuracy: 0.8410\n",
      "Epoch 6/15\n",
      "914/914 [==============================] - 23s 25ms/step - loss: 0.2840 - accuracy: 0.8790 - val_loss: 0.3595 - val_accuracy: 0.8418\n",
      "Epoch 7/15\n",
      "914/914 [==============================] - 23s 25ms/step - loss: 0.2665 - accuracy: 0.8879 - val_loss: 0.3692 - val_accuracy: 0.8412\n",
      "Epoch 8/15\n",
      "914/914 [==============================] - 23s 25ms/step - loss: 0.2488 - accuracy: 0.8954 - val_loss: 0.3845 - val_accuracy: 0.8374\n",
      "Epoch 9/15\n",
      "914/914 [==============================] - 22s 25ms/step - loss: 0.2344 - accuracy: 0.9024 - val_loss: 0.3881 - val_accuracy: 0.8418\n",
      "[BiLSTM_W2V_Frozen] Test Acc: 83.70%\n",
      "Epoch 1/15\n",
      "914/914 [==============================] - 28s 28ms/step - loss: 0.4609 - accuracy: 0.7773 - val_loss: 0.3912 - val_accuracy: 0.8243\n",
      "Epoch 2/15\n",
      "914/914 [==============================] - 25s 28ms/step - loss: 0.3522 - accuracy: 0.8451 - val_loss: 0.3456 - val_accuracy: 0.8496\n",
      "Epoch 3/15\n",
      "914/914 [==============================] - 28s 30ms/step - loss: 0.3098 - accuracy: 0.8669 - val_loss: 0.3345 - val_accuracy: 0.8563\n",
      "Epoch 4/15\n",
      "914/914 [==============================] - 25s 28ms/step - loss: 0.2811 - accuracy: 0.8810 - val_loss: 0.3272 - val_accuracy: 0.8615\n",
      "Epoch 5/15\n",
      "914/914 [==============================] - 25s 28ms/step - loss: 0.2571 - accuracy: 0.8927 - val_loss: 0.3282 - val_accuracy: 0.8641\n",
      "Epoch 6/15\n",
      "914/914 [==============================] - 26s 28ms/step - loss: 0.2382 - accuracy: 0.9022 - val_loss: 0.3296 - val_accuracy: 0.8633\n",
      "Epoch 7/15\n",
      "914/914 [==============================] - 25s 28ms/step - loss: 0.2183 - accuracy: 0.9122 - val_loss: 0.3327 - val_accuracy: 0.8643\n",
      "[BiLSTM_W2V_FineTune] Test Acc: 85.75%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- [FastTextLike] Test Acc: 84.42%\n",
    "- [TextCNN] Test Acc: 86.45%\n",
    "- [BiLSTM] Test Acc: 85.93%\n",
    "- [BiLSTM_W2V_Frozen] Test Acc: 83.70%\n",
    "- [BiLSTM_W2V_FineTune] Test Acc: 85.75%"
   ],
   "id": "7141061ae7a1dbe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:49:28.777536Z",
     "start_time": "2025-08-01T08:49:28.741778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def keras_embedding_to_kv(model, layer_name, index_to_word, special_tokens={'<PAD>','<BOS>','<UNK>','<UNUSED>'}):\n",
    "    \"\"\"Keras Embedding 레이어 가중치를 gensim KeyedVectors로 변환.\"\"\"\n",
    "    W = model.get_layer(layer_name).get_weights()[0]   # (vocab_size, emb_dim)\n",
    "    kv_emb = KeyedVectors(vector_size=W.shape[1])\n",
    "    words, vecs = [], []\n",
    "    # index_to_word: {index: token}\n",
    "    for idx in range(len(index_to_word)):\n",
    "        tok = index_to_word[idx]\n",
    "        if tok in special_tokens:\n",
    "            continue\n",
    "        words.append(tok)\n",
    "        vecs.append(W[idx])\n",
    "    kv_emb.add_vectors(words, np.asarray(vecs))\n",
    "    return kv_emb\n",
    "\n",
    "\n",
    "# 베이스라인 임베딩\n",
    "kv_ft   = keras_embedding_to_kv(m_ft,  'emb',     index_to_word)   # FastText-like\n",
    "kv_bi   = keras_embedding_to_kv(m_bi,  'emb',     index_to_word)   # BiLSTM (rand init)\n",
    "\n",
    "# 사전학습 주입 모델의 임베딩 (동일 토큰 공간)\n",
    "kv_w2v_frozen = keras_embedding_to_kv(m_w2v_frozen, 'emb_pre', index_to_word)\n",
    "kv_w2v_ft     = keras_embedding_to_kv(m_w2v_ft,     'emb_pre', index_to_word)"
   ],
   "id": "e4a7448c376c384d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:51:17.439058Z",
     "start_time": "2025-08-01T08:51:17.395302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def safe_neighbors(kv_obj, word, topn=10):\n",
    "    try:\n",
    "        return kv_obj.most_similar(word, topn=topn)\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "probe = ['영화','재밌','최고','최악','지루','배우','스토리']\n",
    "topn = 5\n",
    "\n",
    "for w in probe:\n",
    "    print(f\"\\n=== '{w}' ===\")\n",
    "    for name, kv_obj in [\n",
    "        ('FastText-like',      kv_ft),\n",
    "        ('BiLSTM(rand)',       kv_bi),\n",
    "        ('W2V Frozen',         kv_w2v_frozen),\n",
    "        ('W2V FineTune',       kv_w2v_ft),\n",
    "        ('External W2V(orig)', kv),\n",
    "    ]:\n",
    "        nbrs = safe_neighbors(kv_obj, w, topn=topn)\n",
    "        if nbrs:\n",
    "            pretty = \", \".join([f\"{t}:{s:.3f}\" for t, s in nbrs])\n",
    "            print(f\"{name:17s} -> {pretty}\")\n",
    "        else:\n",
    "            print(f\"{name:17s} -> (OOV 또는 이웃 없음)\")\n",
    "\n",
    "## W2V Frozen 모델은 가중치를 학습하지 않아서 kv와 값 자체는 동일함"
   ],
   "id": "85a58798b889ad64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== '영화' ===\n",
      "FastText-like     -> 진짜:0.547, 완전:0.543, 이후:0.518, 드라마:0.495, 고:0.493\n",
      "BiLSTM(rand)      -> 음:0.621, 준다:0.609, 점:0.607, 줍니다:0.600, 스러워:0.574\n",
      "W2V Frozen        -> 드라마:0.842, 뮤지컬:0.778, 코미디:0.749, 다큐멘터리:0.740, 헐리우드:0.740\n",
      "W2V FineTune      -> 드라마:0.843, 뮤지컬:0.777, 코미디:0.748, 헐리우드:0.742, 다큐멘터리:0.738\n",
      "External W2V(orig) -> 드라마:0.842, 뮤지컬:0.778, 코미디:0.749, 다큐멘터리:0.740, 헐리우드:0.740\n",
      "\n",
      "=== '재밌' ===\n",
      "FastText-like     -> 수작:0.959, 울컥:0.945, 흠잡:0.944, 이제야:0.943, 완벽:0.941\n",
      "BiLSTM(rand)      -> 완벽:0.923, 굳:0.919, 천재:0.917, 그리움:0.917, 본받:0.916\n",
      "W2V Frozen        -> 재미있:0.905, 멋있:0.868, 웃기:0.831, 예쁘:0.809, 슬프:0.775\n",
      "W2V FineTune      -> 재미있:0.913, 멋있:0.880, 웃기:0.826, 예쁘:0.795, 슬프:0.784\n",
      "External W2V(orig) -> 재미있:0.905, 멋있:0.868, 웃기:0.831, 예쁘:0.809, 슬프:0.775\n",
      "\n",
      "=== '최고' ===\n",
      "FastText-like     -> 수작:0.956, 완벽:0.947, 명작:0.945, 먹먹:0.943, 흥미진진:0.940\n",
      "BiLSTM(rand)      -> 펑펑:0.915, 이제야:0.893, 고인:0.889, 빠져들:0.888, 유쾌:0.884\n",
      "W2V Frozen        -> 역대:0.654, 최악:0.610, 최대:0.600, 최저:0.594, 올해:0.579\n",
      "W2V FineTune      -> 역대:0.657, 최대:0.598, 올해:0.575, 최저:0.574, 우수:0.567\n",
      "External W2V(orig) -> 역대:0.654, 최다:0.614, 최악:0.610, 최대:0.600, 최저:0.594\n",
      "\n",
      "=== '최악' ===\n",
      "FastText-like     -> 차라리:0.983, 졸작:0.978, 허접:0.976, 낭비:0.975, 쓰레기:0.975\n",
      "BiLSTM(rand)      -> 서세원:0.962, 하품:0.961, 먹칠:0.958, 모욕:0.958, 조악:0.953\n",
      "W2V Frozen        -> 최고:0.610, 희대:0.565, 뜻밖:0.560, 엄청난:0.539, 최저:0.532\n",
      "W2V FineTune      -> 희대:0.586, 최고:0.550, 최저:0.544, 뜻밖:0.536, 역대:0.499\n",
      "External W2V(orig) -> 전대미문:0.647, 초유:0.629, 최고:0.610, 희대:0.565, 뜻밖:0.560\n",
      "\n",
      "=== '지루' ===\n",
      "FastText-like     -> 최악:0.954, 노:0.949, 차라리:0.948, 쓰레기:0.947, 허접:0.947\n",
      "BiLSTM(rand)      -> 어설픈:0.917, 아까웠:0.917, 졸음:0.902, 과하:0.900, 실망:0.900\n",
      "W2V Frozen        -> 답답:0.843, 불쾌:0.836, 지저분:0.826, 조용:0.826, 피곤:0.818\n",
      "W2V FineTune      -> 불쾌:0.839, 답답:0.838, 지저분:0.830, 피곤:0.822, 어색:0.817\n",
      "External W2V(orig) -> 답답:0.843, 불쾌:0.836, 지저분:0.826, 조용:0.826, 피곤:0.818\n",
      "\n",
      "=== '배우' ===\n",
      "FastText-like     -> 한참:0.592, 시간:0.574, 이렇게:0.563, .:0.553, 뭘까:0.552\n",
      "BiLSTM(rand)      -> 춘:0.537, 떴:0.524, 갚:0.515, 어유:0.514, 2004:0.512\n",
      "W2V Frozen        -> 가수:0.773, 영화배우:0.744, 여배우:0.741, 연출가:0.740, 성우:0.697\n",
      "W2V FineTune      -> 가수:0.771, 영화배우:0.742, 여배우:0.742, 연출가:0.738, 성우:0.694\n",
      "External W2V(orig) -> 가수:0.773, 코미디언:0.773, 만화가:0.750, 영화배우:0.744, 여배우:0.741\n",
      "\n",
      "=== '스토리' ===\n",
      "FastText-like     -> 고:0.740, 너무:0.729, 여서:0.682, 중:0.675, 이렇게:0.673\n",
      "BiLSTM(rand)      -> 자위:0.736, .-:0.725, 놨다:0.723, 텅:0.720, 댕기:0.720\n",
      "W2V Frozen        -> 줄거리:0.754, 캐릭터:0.725, 시나리오:0.714, 어드벤처:0.670, 아바타:0.665\n",
      "W2V FineTune      -> 줄거리:0.758, 캐릭터:0.725, 시나리오:0.723, 어드벤처:0.666, 아바타:0.663\n",
      "External W2V(orig) -> 줄거리:0.754, 캐릭터:0.725, 시나리오:0.714, 어드벤처:0.670, 아바타:0.665\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T08:51:35.864321Z",
     "start_time": "2025-08-01T08:51:35.860324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def has_word(kv_obj, w):\n",
    "    return kv_obj.has_index_for(w) if hasattr(kv_obj, \"has_index_for\") else (w in getattr(kv_obj, \"key_to_index\", {}))\n",
    "\n",
    "def cos(a, b, eps=1e-8):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a)+eps) / (np.linalg.norm(b)+eps))\n",
    "\n",
    "print(\"\\n[Drift: External W2V(orig) vs W2V FineTune] (코사인 유사도)\")\n",
    "for w in probe:\n",
    "    if has_word(kv, w) and has_word(kv_w2v_ft, w):\n",
    "        print(f\"{w:>6s}: {cos(kv[w], kv_w2v_ft[w]):.3f}\")\n",
    "    else:\n",
    "        print(f\"{w:>6s}: (OOV)\")\n",
    "\n",
    "## word 임베딩 부분이 어느정도로 바뀌었는지 코사인 유사도로 측정"
   ],
   "id": "e657b30ad9a3641b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Drift: External W2V(orig) vs W2V FineTune] (코사인 유사도)\n",
      "    영화: 1.000\n",
      "    재밌: 0.987\n",
      "    최고: 0.999\n",
      "    최악: 0.984\n",
      "    지루: 0.986\n",
      "    배우: 1.000\n",
      "   스토리: 1.000\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- KoNLPy, Mecab을 설치하는게 상당히 힘들었다\n",
    "- 잘 안쓰던 tensorflow를 사용해 중간에 오류 해결하고 수정을 많이 했던 것 같다.\n",
    "- 사전학습된 word2vec을 사용하는 것과 처음부터 학습하는 것의 모델 성능 차이는 의외로 별로 없다.\n",
    "- 데이터의 난이도, 모델의 간단한 구조 등의 이유로 성능은 큰 차이가 없는 것 같다.\n",
    "- 하지만 gensim을 이용해 유사한 단어와 유사도를 확인해보면, 완전히 다른 결과가 나왔다."
   ],
   "id": "eb3397c14a771607"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
